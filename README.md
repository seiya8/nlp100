# nlp100
my solutions of [NLP 100 Exercise](https://nlp100.github.io/ja/)

|Chapter|No.|Title|Python|Ruby|Shell|
|---|---|---|---|---|---|
|[01](https://nlp100.github.io/ja/ch01.html)|00|文字列の逆順||||
||01|「パタトクカシーー」||||
||02|「パトカー」＋「タクシー」＝「パタトクカシーー」||||
||03|円周率||||
||04|元素記号||||
||05|n-gram||||
||06|集合||||
||07|テンプレートによる文生成||||
||08|暗号文||||
||09|Typoglycemia||||
|[02](https://nlp100.github.io/ja/ch02.html)|10|行数のカウント||||
||11|タブをスペースに置換||||
||12|1列目をcol1.txtに，2列目をcol2.txtに保存||||
||13|col1.txtとcol2.txtをマージ||||
||14|先頭からN行を出力||||
||15|末尾のN行を出力||||
||16|ファイルをN分割する||||
||17|１列目の文字列の異なり||||
||18|各行を3コラム目の数値の降順にソート||||
||19|各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる||||
|[03](https://nlp100.github.io/ja/ch03.html)|20|JSONデータの読み込み||||
||21|カテゴリ名を含む行を抽出||||
||22|カテゴリ名の抽出||||
||23|セクション構造||||
||24|ファイル参照の抽出||||
||25|テンプレートの抽出||||
||26|強調マークアップの除去||||
||27|内部リンクの除去||||
||28|MediaWikiマークアップの除去||||
||29|国旗画像のURLを取得する||||
|[04](https://nlp100.github.io/ja/ch04.html)|30|形態素解析結果の読み込み||||
||31|動詞||||
||32|動詞の基本形||||
||33|「AのB」||||
||34|名詞の連接||||
||35|単語の出現頻度||||
||36|頻度上位10語||||
||37|「猫」と共起頻度の高い上位10語||||
||38|ヒストグラム||||
||39|Zipfの法則||||
|[05](https://nlp100.github.io/ja/ch05.html)|40|係り受け解析結果の読み込み（形態素）||||
||41|係り受け解析結果の読み込み（文節・係り受け）||||
||42|係り元と係り先の文節の表示||||
||43|名詞を含む文節が動詞を含む文節に係るものを抽出||||
||44|係り受け木の可視化||||
||45|動詞の格パターンの抽出||||
||46|動詞の格フレーム情報の抽出||||
||47|機能動詞構文のマイニング||||
||48|名詞から根へのパスの抽出||||
||49|名詞間の係り受けパスの抽出||||
|[06](https://nlp100.github.io/ja/ch06.html)|50|データの入手・整形||||
||51|特徴量抽出||||
||52|学習||||
||53|予測||||
||54|正解率の計測||||
||55|混同行列の作成||||
||56|適合率，再現率，F1スコアの計測||||
||57|特徴量の重みの確認||||
||58|正則化パラメータの変更||||
||59|ハイパーパラメータの探索||||
|[07](https://nlp100.github.io/ja/ch07.html)|60|単語ベクトルの読み込みと表示||||
||61|単語の類似度||||
||62|類似度の高い単語10件||||
||63|加法構成性によるアナロジー||||
||64|アナロジーデータでの実験||||
||65|アナロジータスクでの正解率||||
||66|WordSimilarity-353での評価||||
||67|k-meansクラスタリング||||
||68|Ward法によるクラスタリング||||
||69|t-SNEによる可視化||||
|[08](https://nlp100.github.io/ja/ch08.html)|70|単語ベクトルの和による特徴量||||
||71|単層ニューラルネットワークによる予測||||
||72|損失と勾配の計算||||
||73|確率的勾配降下法による学習||||
||74|正解率の計測||||
||75|損失と正解率のプロット||||
||76|チェックポイント||||
||77|ミニバッチ化||||
||78|GPU上での学習||||
||79|多層ニューラルネットワーク||||
|[09](https://nlp100.github.io/ja/ch09.html)|80|ID番号への変換||||
||81|RNNによる予測||||
||82|確率的勾配降下法による学習||||
||83|ミニバッチ化・GPU上での学習||||
||84|単語ベクトルの導入||||
||85|双方向RNN・多層化||||
||86|(CNN)||||
||87|確率的勾配降下法によるCNNの学習||||
||88|パラメータチューニング||||
||89|事前学習済み言語モデルからの転移学習||||
|[010](https://nlp100.github.io/ja/ch10.html)|90|データの準備||||
||91|機械翻訳モデルの訓練||||
||92|機械翻訳モデルの適用||||
||93|BLEUスコアの計測||||
||94|ビーム探索||||
||95|サブワード化||||
||96|学習過程の可視化||||
||97|ハイパー・パラメータの調整||||
||98|ドメイン適応||||
||99|翻訳サーバの構築||||
